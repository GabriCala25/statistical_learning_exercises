{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729e6c40-3562-4411-8184-770bcc267645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize ,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe10b3e-863d-474c-9842-9b4c17e79972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate ,\n",
    "KFold ,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc4ec3-31ee-47fb-aa3e-e5ca594cde99",
   "metadata": {},
   "source": [
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e1dc69-cdf2-4ef1-8a63-3dee162508e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to estimate the test error rates that results from fitting various linear models on the auto data set\n",
    "Auto = load_data('Auto')\n",
    "Auto_train , Auto_valid = train_test_split(Auto , test_size=196, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb2a43f-7247-4d5d-8905-82e564ad1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the linear regression using just the training dataset\n",
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train , X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f458c46-5be8-4b5f-af26-4d18d325ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "# MSE of the model\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc90cf2-3c88-4ec6-b8a1-d125c64a0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can also estimate the validation error for higher degree polynomial regressions by creating the following function\n",
    "def evalMSE(terms ,response ,train , test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train , X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615910ce-0a12-46fb-bfc3-91384bc42a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                        'mpg',\n",
    "                        Auto_train ,\n",
    "                        Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d221d48e-7aac-4f78-b96e-4342960a0318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train , Auto_valid = train_test_split(Auto ,test_size=196, random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],'mpg',Auto_train , Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6ca14a-1c59-4035-bf92-09022f01bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn_sm is a wrapper that enables us to easily use cross_validation tools.\n",
    "# its first argument is a model from the library statsmodels; \n",
    "# it can take two additional arguments: model_str (to specify a formula) or model_args (dictionary of additional arguments to specify a family argument)\n",
    "\n",
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "\n",
    "# the arguments of cross_validate are: object with proper fit, predict or score methods; X features; Y response;\n",
    "#cv specifies K results in K-fold cross validation\n",
    "cv_results = cross_validate(hp_model, X, Y, cv = Auto.shape[0])\n",
    "\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f5d243-abf7-411d-9cb9-c85c0abc04b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443034, 19.0332226 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We automate the procedure for increasingly complex polynomial fits\n",
    "#We use the outer method after a math operation; \n",
    "# it takes two arrays as arguments and then forms a larger array where the operationis applied to each pair of elements of the two arrays.\n",
    "\n",
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d + 1))\n",
    "    M_CV = cross_validate(M, X, Y, cv = Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fbb7e0-ff9b-448e-9a05-86c2d76e50b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae94276-2705-4dd4-88b2-21f7649cb938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848404, 19.13720771])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use KFold to partition with cv < n\n",
    "\n",
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M, X, Y, cv = cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c30775fa-9ffb-4cd3-85a5-acb24c0b0bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ShuffleSplit function helps in implementing the validation set approach as K-Fold cross-validation\n",
    "validation = ShuffleSplit(n_splits = 1, test_size = 196, random_state = 0)\n",
    "results = cross_validate(hp_model, Auto.drop(['mpg'], axis = 1), Auto['mpg'], cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a9d567b-4e28-4bec-93d5-356aa3dd54bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034168, 1.421845094109181)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we estimate the variability in the test error\n",
    "validation = ShuffleSplit(n_splits = 10, test_size = 196, random_state = 0)\n",
    "results = cross_validate(hp_model, Auto.drop(['mpg'], axis = 1), Auto['mpg'], cv = validation)\n",
    "\n",
    "# the standard deviation is not a valid estimate of the sampling variability of the mean test score or the individual scores;\n",
    "# this is due to the randomly-selected training samples which overlaps hence introduces correlation;\n",
    "# however, it gives an idea of the MonteCarlo variation\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797aa05-8d9c-43b7-9984-59dc56c9da78",
   "metadata": {},
   "source": [
    "#### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b1bc3e-076b-4d5f-a9c9-5f4f2df6914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function for its use in estimating standard error when our data is stored in a dataframe\n",
    "# The goal is to estimate the sampling variance of the parameter alpha;\n",
    "# We assume the dataframe D to have column X and Y, as well as a vector idxindicating which observations should be used to estimate alpha.\n",
    "# The function returns an estimate for alpha based on the formula seen in theory\n",
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X', 'Y']].loc[idx], rowvar = False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0] + cov_[1,1] - 2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6f3c2e-1170-40dd-9452-2fccc0ded865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I apply the function to the loaded Dataframe considering all 100 observations\n",
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e083620-8129-407b-8f5f-ddd1724f2081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now randomly select 100 observations from range(100), but with replacement as true, so that a new dataset is built\n",
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio, rng.choice(100, 100, replace = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4794d68-5fec-4cad-a6a6-06928a614762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can generalize the process to create a simple function boot_SE()\n",
    "def boot_SE(func, D, n=None, B=1000, seed = 0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccaebceb-5790-4860-b2a4-7bf448b1b072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277516"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we try the function to evaluate the accuracy of our estimate of alpha using B = 1000;\n",
    "alpha_SE = boot_SE(alpha_func, Portfolio, B=1000, seed = 0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4821f074-73c3-4098-8035-effcfa88b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we use the bootrastrap approach to estimate the variability of the coefficient estimates and predictions from a statistical learning method;\n",
    "# we use clone function to make a copy of the formula that can be refit to the new dataframe\n",
    "# in this case we created a specific bootstraping for regression models\n",
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b5bd0b3-2e25-4be2-a82e-135d337a1d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m      \u001b[0mhp_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mCall signature:\u001b[0m \u001b[0mhp_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mType:\u001b[0m           partial\n",
       "\u001b[1;31mString form:\u001b[0m    functools.partial(<function boot_OLS at 0x0000016565206CA0>, ModelSpec(terms=['horsepower']), 'mpg')\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\functools.py\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "partial(func, *args, **keywords) - new function with partial application\n",
       "of the given arguments and keywords."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the first two arguments do not change --> we'd like to freeze them --> we use partial function from fucntools library;\n",
    "# we do that to have ideal input for boot_SE func defined before;\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n",
    "hp_func?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7c32ad8-cd7f-4d0c-8cd4-0c21bdd5bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now hp_func is ready to create bootsrap estimates;\n",
    "# we test it on 10 samples\n",
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto, rng.choice(392, 392, replace = True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fd69554-8f90-4d0d-8235-691a80fc603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.848807\n",
       "horsepower    0.007352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we use boot_SE to compute 1000 bootstrap estimates\n",
    "hp_se = boot_SE(hp_func, Auto, B = 1000, seed = 10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a61ac7c-c917-43ac-b127-e1ba81781556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we compare results with the standard formulas;\n",
    "# there's a difference, but bootstrap is more reliable, since it has less assumptions\n",
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bae3b68-69e8-4eed-8489-369342585af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  2.067840\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.033019\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model\n",
    "\n",
    "quad_model = MS([poly('horsepower', 2, raw = True)])\n",
    "quad_func = partial(boot_OLS, quad_model, 'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21af8a6c-c1c3-48b7-a508-263e1545cfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We compare results to the standard ones\n",
    "M = sm.OLS(Auto['mpg'], quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
